{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21597c1f-fcbc-402c-a8c4-b4e42a7b9f7d",
   "metadata": {},
   "source": [
    "# MMS Auralization with spaudiopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf01330c-53fc-4968-af61-7fa3c3f5bd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import spaudiopy as spa\n",
    "import IPython\n",
    "\n",
    "import pandas as pd\n",
    "import urllib.request # for pulling audifications and plots directly from CDAWeb\n",
    "import wget # for downloading audifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e55f0a-0688-49fd-93a8-9f310d99df0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampling frequency\n",
    "fs = 48000\n",
    "# define a mono input signal:\n",
    "sig_in = pd.read_csv('output/THG_L2_MAG_PG0__000_000_Output_mono.csv')['M'].to_numpy()\n",
    "IPython.display.Audio(sig_in, rate = fs)          # play audio in Jupyter notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a60e0f-7b65-4f4b-8d98-b1520b1bacb1",
   "metadata": {},
   "source": [
    "## Load loudspeaker layout, specific to instrumentation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309abf35-f5cf-41e0-8854-40f1aa602b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a loudspeaker layout\n",
    "# ls_layout = spa.io.load_layout('ls_layouts/Aalto_subset_C.json')\n",
    "ls_layout = spa.io.load_layout('ls_layouts/MMS.json')\n",
    "ls_layout.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75fbfd70-bcb8-4bc5-b07c-fd38e1cd5e8e",
   "metadata": {},
   "source": [
    "## Set up signals array \n",
    "4 channels x number of samples.\n",
    "\n",
    "Our data: \n",
    "\n",
    "Start: `2016/12/09 09:00:00.000`\n",
    "Stop: `2016/12/09 09:05:00.000`\n",
    "\n",
    "https://svs.gsfc.nasa.gov/4639"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703e18a3-1796-4598-868c-b0d50e54e66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define auralization (front)\n",
    "src_coords = [1, 10, -50]\n",
    "# define decoding, using vbap as simple example\n",
    "ls_gains = spa.decoder.vbap(src_coords, ls_layout)\n",
    "ls_sigs = ls_layout.loudspeaker_signals(ls_gains, sig_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a66f73-6c77-4ae7-a46a-d09d2f74ede8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_sigs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5ff49d-6a07-4d6c-8372-99aa8faf5a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(ls_sigs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410d8442-025e-4954-81fa-aeb8c2d50fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/MMS1_SCM_BRST_L2_SCB_4142755_000_000_Output_mono.csv')\n",
    "sig1 = df['M'].to_numpy()\n",
    "df = pd.read_csv('data/MMS2_SCM_BRST_L2_SCB_4142755_001_000_Output_mono.csv')\n",
    "sig2 = df['M'].to_numpy()\n",
    "df = pd.read_csv('data/MMS3_SCM_BRST_L2_SCB_4142755_002_000_Output_mono.csv')\n",
    "sig3 = df['M'].to_numpy()\n",
    "df = pd.read_csv('data/MMS4_SCM_BRST_L2_SCB_4142755_003_000_Output_mono.csv')\n",
    "sig4 = df['M'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607c1194-19eb-435f-a56f-b6c1d0c7e90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sig1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9feb609d-9a4f-4b98-8507-201b707843ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "sig2 = sig2[:len(sig1)]\n",
    "sig3 = sig3[:len(sig1)]\n",
    "sig4 = sig4[:len(sig1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c9f476-19e5-473a-8bed-60128a51464b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sig3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991f4f97-2212-4ca6-b644-c84e62c8c83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sig4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999c1d3a-d819-4196-8d0e-3cafcd703cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_sigs = np.stack((sig1, sig2, sig3, sig4), axis=0)\n",
    "ls_sigs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7f43ea-1460-48b1-b58d-4e6eaddf95c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('data/MMS2_SCM_BRST_L2_SCHB_4013143.csv', on_bad_lines='warn')\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2066ab11-08b5-41b1-b1f6-aad43b41e29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from cdasws import CdasWs\n",
    "# cdas = CdasWs()\n",
    "\n",
    "# #  Edit the following vars, time variables, and printing to suit your environment\n",
    "# # (spacepy or cdflib) and needs.\n",
    "# vars = ['mms2_scm_acb_gse_scb_brst_l2','mms2_scm_qf_scm123_scb_brst_l2']\n",
    "# time = ['2016-12-09T09:00:00.000Z', '2016-12-09T09:00:30.000Z']\n",
    "# status, data = cdas.get_data('MMS2_SCM_BRST_L2_SCB', vars, time[0], time[1])\n",
    "\n",
    "# # If spacepy was installed\n",
    "# print(data['mms2_scm_acb_gse_scb_brst_l2'])\n",
    "# print(data['mms2_scm_acb_gse_scb_brst_l2'].attrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56007aa-ee5c-48dc-b5ab-20ee36a0fcd4",
   "metadata": {},
   "source": [
    "## Binauralize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08a04c2-77fb-40f0-a512-76638da4eafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # define auralization (front)\n",
    "# src_coords = [1, 10, -50]\n",
    "# # define decoding, using vbap as simple example\n",
    "# ls_gains = spa.decoder.vbap(src_coords, ls_layout)\n",
    "# ls_sigs = ls_layout.loudspeaker_signals(ls_gains, sig_in)\n",
    "\n",
    "# binaural simulation of this setup\n",
    "s_left, s_right = ls_layout.binauralize(ls_sigs, fs)\n",
    "\n",
    "# for convenience we could now make a signal object and listen to it\n",
    "# spa.sig.MultiSignal([s_left, s_right], fs=fs).play()\n",
    "\n",
    "IPython.display.Audio([s_left, s_right],rate=fs)\n",
    "# TODO: Save wav file with fs = 22000 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359ecbe2-6f3f-4419-8157-8e8f93c150ef",
   "metadata": {},
   "source": [
    "### Code to convert audified files to numpy arrays"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c105f547-b6f1-4ae7-b1f1-4be7e6bff053",
   "metadata": {},
   "source": [
    "# from https://github.com/Lukious/wav-to-csv/tree/master\n",
    "\n",
    "import sys, os, os.path\n",
    "from scipy.io import wavfile\n",
    "import pandas as pd\n",
    "\n",
    "input_filename = input(\"Input file number:\")\n",
    "if input_filename[-3:] != 'wav':\n",
    "    print('WARNING!! Input File format should be *.wav')\n",
    "    sys.exit()\n",
    "\n",
    "samrate, data = wavfile.read(str(input_filename))\n",
    "print('Load is Done! \\n')\n",
    "\n",
    "wavData = pd.DataFrame(data)\n",
    "\n",
    "if len(wavData.columns) == 2:\n",
    "    print('Stereo .wav file\\n')\n",
    "    wavData.columns = ['R', 'L']\n",
    "    stereo_R = pd.DataFrame(wavData['R'])\n",
    "    stereo_L = pd.DataFrame(wavData['L'])\n",
    "    print('Saving...\\n')\n",
    "    stereo_R.to_csv(str(input_filename[:-4] + \"_Output_stereo_R.csv\"), mode='w')\n",
    "    stereo_L.to_csv(str(input_filename[:-4] + \"_Output_stereo_L.csv\"), mode='w')\n",
    "    # wavData.to_csv(\"Output_stereo_RL.csv\", mode='w')\n",
    "    print('Save is done ' + str(input_filename[:-4]) + '_Output_stereo_R.csv , '\n",
    "                          + str(input_filename[:-4]) + '_Output_stereo_L.csv')\n",
    "\n",
    "elif len(wavData.columns) == 1:\n",
    "    print('Mono .wav file\\n')\n",
    "    wavData.columns = ['M']\n",
    "\n",
    "    wavData.to_csv(str(input_filename[:-4] + \"_Output_mono.csv\"), mode='w')\n",
    "\n",
    "    print('Save is done ' + str(input_filename[:-4]) + '_Output_mono.csv')\n",
    "\n",
    "else:\n",
    "    print('Multi channel .wav file\\n')\n",
    "    print('number of channel : ' + len(wavData.columns) + '\\n')\n",
    "    wavData.to_csv(str(input_filename[:-4] + \"Output_multi_channel.csv\"), mode='w')\n",
    "\n",
    "    print('Save is done ' + str(input_filename[:-4]) + 'Output_multi_channel.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
